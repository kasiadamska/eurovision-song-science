{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78896a9b",
   "metadata": {},
   "source": [
    "## YouTube features\n",
    "\n",
    "This notebook reads a CSV file containing a list of YouTube video links (must have a column named \"pre_contest_url\").\n",
    "\n",
    "\n",
    "Extracts metadata for each video using yt_dlp, including:\n",
    "- Video title\n",
    "- Channel name\n",
    "- Upload date\n",
    "- Total views, Likes, Comments\n",
    "- Days since upload\n",
    "- Views-per-day ratio\n",
    "- Extracts and analyzes the YouTube heatmap (if available), which represents the â€œmost replayedâ€ segments of the video.\n",
    "\n",
    "\n",
    "Computes several features from the heatmap:\n",
    "- ðŸ“Š Average replay score (average_value)\n",
    "- ðŸ“ˆ Skewness of the replay distribution (skewness_value)\n",
    "- ðŸ”€ Smoothness of the curve using: Mean of absolute first differences and Variance of first differences\n",
    "- ðŸ“ Time position of the peak (most replayed moment), expressed as a percentage of total video length\n",
    "- ðŸ§  Count of meaningful local replay peaks, based on prominence\n",
    "- ðŸ•’ Time locations of additional peaks (if more than one)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88acc721",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install yt_dlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b715bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yt_dlp\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from scipy.stats import skew\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "# === INPUT/OUTPUT SETTINGS ===\n",
    "input_csv = \"input_file.csv\"  # Replace with your input CSV path\n",
    "output_csv = \"output_file.csv\"  # Replace with your output CSV path\n",
    "\n",
    "# === LOAD INPUT ===\n",
    "df = pd.read_csv(input_csv)\n",
    "\n",
    "# Check if t he required column exists\n",
    "if \"pre_contest_url\" not in df.columns:\n",
    "    raise ValueError(\"The input CSV must contain a column named 'pre_contest_url'.\")\n",
    "\n",
    "# === FUNCTIONS ===\n",
    "\n",
    "# Extract video info using yt_dlp\n",
    "def get_video_info(link):\n",
    "    try:\n",
    "        with yt_dlp.YoutubeDL({'quiet': True}) as ydl:\n",
    "            info = ydl.extract_info(link, download=False)\n",
    "            video_title = info.get('title', 'Unknown')\n",
    "            channel_name = info.get('uploader', 'Unknown')\n",
    "            upload_date_str = info.get('upload_date', 'Unknown')\n",
    "            total_views = info.get('view_count', 0)\n",
    "            like_count = info.get('like_count', 'Unknown')\n",
    "            comment_count = info.get('comment_count', 'Unknown')\n",
    "\n",
    "            # Upload date and days since upload\n",
    "            if upload_date_str != 'Unknown':\n",
    "                upload_date = datetime.strptime(upload_date_str, '%Y%m%d')\n",
    "                days_since_upload = (datetime.now() - upload_date).days\n",
    "            else:\n",
    "                upload_date = \"Unknown\"\n",
    "                days_since_upload = \"Unknown\"\n",
    "\n",
    "            # Views per day\n",
    "            if days_since_upload != \"Unknown\" and days_since_upload > 0:\n",
    "                views_per_day = total_views / days_since_upload\n",
    "            else:\n",
    "                views_per_day = total_views\n",
    "\n",
    "            # Extract heatmap if available\n",
    "            heatmap_data = info.get('heatmap', None)\n",
    "\n",
    "            return {\n",
    "                \"Video Title\": video_title,\n",
    "                \"Channel Name\": channel_name,\n",
    "                \"Upload Date\": upload_date if upload_date == \"Unknown\" else upload_date.strftime('%Y-%m-%d'),\n",
    "                \"Total Views\": total_views,\n",
    "                \"Likes\": like_count,\n",
    "                \"Comments\": comment_count,\n",
    "                \"Days Since Upload\": days_since_upload,\n",
    "                \"Views per Day Ratio\": round(views_per_day, 2) if isinstance(views_per_day, float) else views_per_day,\n",
    "                \"Link\": link,\n",
    "                \"Heatmap\": heatmap_data  # Save heatmap raw\n",
    "            }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {link}: {e}\")\n",
    "        return {\n",
    "            \"Video Title\": \"Error\",\n",
    "            \"Channel Name\": \"Error\",\n",
    "            \"Upload Date\": \"Error\",\n",
    "            \"Total Views\": \"Error\",\n",
    "            \"Likes\": \"Error\",\n",
    "            \"Comments\": \"Error\",\n",
    "            \"Days Since Upload\": \"Error\",\n",
    "            \"Views per Day Ratio\": \"Error\",\n",
    "            \"Link\": link,\n",
    "            \"Heatmap\": None\n",
    "        }\n",
    "\n",
    "# Analyze heatmap\n",
    "def extract_heatmap_features(heatmap):\n",
    "    if heatmap is None or len(heatmap) == 0:\n",
    "        # If no heatmap available, return NaN\n",
    "        return {\n",
    "            \"average_value\": np.nan,\n",
    "            \"skewness_value\": np.nan,\n",
    "            \"mean_abs_difference\": np.nan,\n",
    "            \"variance_difference\": np.nan,\n",
    "            \"primary_peak_percentage\": np.nan,\n",
    "            \"number_of_maxima\": np.nan,\n",
    "            \"additional_peak_percentages\": np.nan\n",
    "        }\n",
    "    \n",
    "    values = np.array([point['value'] for point in heatmap])\n",
    "    start_times = np.array([point['start_time'] for point in heatmap])\n",
    "    end_times = np.array([point['end_time'] for point in heatmap])\n",
    "    mid_times = (start_times + end_times) / 2\n",
    "\n",
    "    avg_value = np.mean(values)\n",
    "    skewness_value = skew(values)\n",
    "    difference = np.diff(values)\n",
    "    mean_abs_difference = np.mean(np.abs(difference))\n",
    "    variance_difference = np.var(difference)\n",
    "\n",
    "    total_duration = end_times[-1]\n",
    "    peak_indices = np.where(values == np.max(values))[0]\n",
    "    primary_peak_time_percentage = (mid_times[peak_indices[0]] / total_duration) * 100\n",
    "\n",
    "    # Find peaks with minimum prominence\n",
    "    peaks, properties = find_peaks(values, prominence=0.1)\n",
    "\n",
    "    # Always include the global peak\n",
    "    if peak_indices[0] not in peaks:\n",
    "        peaks = np.append(peaks, peak_indices[0])\n",
    "\n",
    "    num_maxima = len(peaks)\n",
    "\n",
    "    if num_maxima > 1:\n",
    "        additional_peak_times = (mid_times[peaks] / total_duration) * 100\n",
    "        # Convert additional_peak_times to a list if it's a NumPy array\n",
    "        additional_peak_times = additional_peak_times.tolist() if isinstance(additional_peak_times, np.ndarray) else additional_peak_times\n",
    "    else:\n",
    "        additional_peak_times = []\n",
    "\n",
    "    return {\n",
    "        \"average_value\": avg_value,\n",
    "        \"skewness_value\": skewness_value,\n",
    "        \"mean_abs_difference\": mean_abs_difference,\n",
    "        \"variance_difference\": variance_difference,\n",
    "        \"primary_peak_percentage\": primary_peak_time_percentage,\n",
    "        \"number_of_maxima\": num_maxima,\n",
    "        \"additional_peak_percentages\": additional_peak_times\n",
    "    }\n",
    "\n",
    "# === MAIN EXECUTION ===\n",
    "\n",
    "# List to collect everything\n",
    "video_data = []\n",
    "\n",
    "# Process each video\n",
    "for index, row in df.iterrows():\n",
    "    link = row[\"pre_contest_url\"]\n",
    "    video_info = get_video_info(link)\n",
    "    heatmap_features = extract_heatmap_features(video_info.pop(\"Heatmap\"))  # Remove heatmap raw, replace with features\n",
    "    combined_data = {**video_info, **heatmap_features}\n",
    "    video_data.append(combined_data)\n",
    "    print(f\"Processed: {link}\")\n",
    "\n",
    "# Save results to CSV\n",
    "result_df = pd.DataFrame(video_data)\n",
    "result_df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"âœ… All results saved to {output_csv}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
